{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cee9145-db01-403d-8e2f-ba0fc5331fd9",
   "metadata": {},
   "source": [
    "# Modeling Exercises\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d04df-ef4a-4f4b-a105-1f1a1cd51b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from mall_wrangle import wrangle_mall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5379f92-016d-4cc6-b156-d9c9cb3fec85",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690f6ea-3940-44bf-8feb-03958112ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data('iris')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acba4c61-061a-46d4-b5e1-e51fdeac0c6c",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "### Let's fix the column names by making everything lower case and replacing the dot separator with and underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc63f02-5c9c-4827-ad98-9e924d381593",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_names = []\n",
    "\n",
    "for col in df.columns:\n",
    "    new_col_names.append(col.lower().replace('.', '_'))\n",
    "    \n",
    "df.columns = new_col_names\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5c0fe-bc61-4769-b83b-dca13da785de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['petal_length', 'petal_width']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d13d9d4-6fb0-4d29-947c-342ff3f99e71",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### Create and Fit cluster model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf281aac-43cd-4cdd-96b9-4d01ecc6915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "\n",
    "clusters = kmeans.predict(X)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b001d45b-2b9c-41f9-b06e-a13f279c849a",
   "metadata": {},
   "source": [
    "### Add cluster to our original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9c510-f558-4a8c-80eb-d15002d56bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = clusters\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd03aa7-d90b-48ae-99ec-c5025ac22104",
   "metadata": {},
   "source": [
    "### Visualize Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73750cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('species').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a9f50-4868-4e7d-8d9f-1d3923562573",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 9), sharex=True, sharey=True)\n",
    "\n",
    "for species, subset in df.groupby('species'):\n",
    "    axs[0].scatter(subset.petal_length, subset.petal_width, label=species)\n",
    "    \n",
    "axs[0].legend()\n",
    "axs[0].set(title='Actual Species')\n",
    "    \n",
    "for cluster_n in df.cluster.sort_values().unique():\n",
    "    axs[1].scatter(df[df.cluster == cluster_n].petal_length, df[df.cluster == cluster_n].petal_width, label=f'cluster_{cluster_n}')\n",
    "\n",
    "axs[1].legend()\n",
    "axs[1].set(title=\"K-Means Clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4354f4-867d-421f-b69e-dee26183dfac",
   "metadata": {},
   "source": [
    "### Use elbow method to determine cluster number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2b049-81db-4faa-9cd1-1679cfba0a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e0095a-01b6-4a4b-a7b0-9616b55a91c3",
   "metadata": {},
   "source": [
    "#### This graph seems to show a drop off in inertia around **k=4** so let's look at around there to see what seems best\n",
    "\n",
    "### Visuals cluster around k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383233ef-dd1a-4e92-b862-3104890d4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(13, 13), sharex=True, sharey=True)\n",
    "\n",
    "for ax, k in zip(axs.ravel(), range(2, 6)):\n",
    "    clusters = KMeans(k).fit(X).predict(X)\n",
    "    ax.scatter(X.petal_length, X.petal_width, c=clusters)\n",
    "    ax.set(title='k = {}'.format(k), xlabel='petal length', ylabel='petal width')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73a356a-15c0-4791-860c-3cd6dd55532f",
   "metadata": {},
   "source": [
    "### Clustering on 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3991c41-4629-49e8-9b49-2f09dc292c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['petal_length', 'petal_width', 'sepal_length']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e313a04-ce0d-4d78-b700-b4fc8c396dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "\n",
    "clusters = kmeans.predict(X)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36922d4b-c96d-4c50-be55-040f0966425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['three_feature_cluster'] = clusters\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57523050-6a4c-4b4a-a16e-31837a960d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(22, 11))\n",
    "\n",
    "for species, subset in df.groupby('species'):\n",
    "    axs[0,0].scatter(subset.petal_length, subset.petal_width, label=species)\n",
    "    \n",
    "axs[0,0].legend()\n",
    "axs[0,0].set(title='Actual Species with petal_length and petal_width')\n",
    "    \n",
    "for cluster_n in df.three_feature_cluster.sort_values().unique():\n",
    "    axs[0,1].scatter(df[df.three_feature_cluster == cluster_n].petal_length, df[df.three_feature_cluster == cluster_n].petal_width, label=f'cluster_{cluster_n}')\n",
    "\n",
    "axs[0,1].legend()\n",
    "axs[0,1].set(title=\"K-Means Clusters with petal_length and petal_width\")\n",
    "\n",
    "for species, subset in df.groupby('species'):\n",
    "    axs[1,0].scatter(subset.petal_width, subset.sepal_length, label=species)\n",
    "    \n",
    "axs[1,0].legend()\n",
    "axs[1,0].set(title='Actual Species with petal_width and sepal_length')\n",
    "\n",
    "for cluster_n in df.three_feature_cluster.sort_values().unique():\n",
    "    axs[1,1].scatter(df[df.three_feature_cluster == cluster_n].petal_width, df[df.three_feature_cluster == cluster_n].sepal_length, label=f'cluster_{cluster_n}')\n",
    "\n",
    "axs[1,1].legend()\n",
    "axs[1,1].set(title=\"K-Means Clusters with petal_width and sepal_length\")\n",
    "\n",
    "for species, subset in df.groupby('species'):\n",
    "    axs[2,0].scatter(subset.petal_length, subset.sepal_length, label=species)\n",
    "    \n",
    "axs[2,0].legend()\n",
    "axs[2,0].set(title='Actual Species with petal_length and sepal_length')\n",
    "\n",
    "for cluster_n in df.three_feature_cluster.sort_values().unique():\n",
    "    axs[2,1].scatter(df[df.three_feature_cluster == cluster_n].petal_length, df[df.three_feature_cluster == cluster_n].sepal_length, label=f'cluster_{cluster_n}')\n",
    "\n",
    "axs[2,1].legend()\n",
    "axs[2,1].set(title=\"K-Means Clusters with petal_length and sepal_length\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312d8a69-5f49-4e75-8318-1cc929269fec",
   "metadata": {},
   "source": [
    "## Clustering the Mall Dataset\n",
    "\n",
    "### Bring in our modeling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5499ed-9416-450b-be25-2de3a3d612a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, train, validate, test = wrangle_mall_df()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771edf6-1497-48cb-afec-078f230ea447",
   "metadata": {},
   "source": [
    "### Let's take a quick look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c9c947-9b58-4f35-a8d2-c29765e564c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train.drop(columns='is_male'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4808c-d68c-444f-b3cd-05cd2ce030d7",
   "metadata": {},
   "source": [
    "### I see a really nice X shape in the combonation of spending score and annual_income, so let's start with clustering on those features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709ed07-f8d1-4caf-a99f-7f10fb055f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['spending_score', 'annual_income']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98696227-3d93-4a90-b9fd-34f452437963",
   "metadata": {},
   "source": [
    "### Create our clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b3501b-bef4-4fe6-bf92-22e7492598f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(X)\n",
    "\n",
    "clusters = kmeans.predict(X)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db7c66-2993-4143-9a69-2bd77c8ad183",
   "metadata": {},
   "source": [
    "### Add our clusters onto the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52807e-5f93-4dca-a1b1-bff41ce98cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cluster'] = clusters\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4120e1ab-11ca-4b15-b411-a0af3c88db8e",
   "metadata": {},
   "source": [
    "### Visualize our clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7ba27-95af-4e89-bbe7-27bc61bc87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "for cluster_n in train.cluster.sort_values().unique():\n",
    "    plt.scatter(train[train.cluster == cluster_n].spending_score, train[train.cluster == cluster_n].annual_income, label=f'cluster_{cluster_n}')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"K-Means Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c936c1-befc-4f24-8336-1b680e8e5937",
   "metadata": {},
   "source": [
    "### Use the elbow method to determine if we have the appropriate number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd867c-133d-4143-8b17-58af66f3fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b365c3-ff12-470a-8fc7-e1066fa84ba9",
   "metadata": {},
   "source": [
    "#### This seem to show the elbow around five so lets check around there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f84b238-1dac-42c2-9b71-0e7a28602d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(13, 13), sharex=True, sharey=True)\n",
    "\n",
    "for ax, k in zip(axs.ravel(), range(3, 7)):\n",
    "    clusters = KMeans(k).fit(X).predict(X)\n",
    "    ax.scatter(X.spending_score, X.annual_income, c=clusters)\n",
    "    ax.set(title='k = {}'.format(k), xlabel='spending_score', ylabel='annual_income')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35534d32-8335-4afc-a369-d16511578b4b",
   "metadata": {},
   "source": [
    "#### It looks like 5 clusters is good for capturing distinct groups in our data\n",
    "\n",
    "## Clustering the Scaled Mall Dataset (Does scaling make a difference?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dca055",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70902be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.drop(columns='cluster').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd545bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5458d59-22f3-4bdf-b324-58ea111fe172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(train2)\n",
    "\n",
    "train_scaled = scaler.transform(train2)\n",
    "validate_scaled = scaler.transform(validate)\n",
    "test_scaled = scaler.transform(test)\n",
    "\n",
    "train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e5116",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = pd.DataFrame(train_scaled, columns=train2.columns.values).set_index([train2.index.values])\n",
    "validate_scaled = pd.DataFrame(validate_scaled, columns=validate.columns.values).set_index([validate.index.values])\n",
    "test_scaled = pd.DataFrame(test_scaled, columns=test.columns.values).set_index([test.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be359f-d066-433c-b2d6-712ca44b6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_scaled.drop(columns='is_male'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005aff1e-49e9-4406-bb35-cac5d944d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['spending_score', 'annual_income']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c5e49-213b-415b-bbc9-8374b962d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(X)\n",
    "\n",
    "clusters = kmeans.predict(X)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e13da-c2e4-4330-bb79-f58e18aca3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled['cluster'] = clusters\n",
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1d91e-0cac-4457-877d-2a967271723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "for cluster_n in train_scaled.cluster.sort_values().unique():\n",
    "    plt.scatter(train_scaled[train_scaled.cluster == cluster_n].spending_score, \n",
    "                train_scaled[train_scaled.cluster == cluster_n].annual_income, \n",
    "                label=f'cluster_{cluster_n}'\n",
    "               )\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"K-Means Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c5528-9113-4064-b23e-420ad51ce67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb5084-bf29-43f5-a243-d19ed2935cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(13, 13), sharex=True, sharey=True)\n",
    "\n",
    "for ax, k in zip(axs.ravel(), range(3, 7)):\n",
    "    clusters = KMeans(k).fit(X).predict(X)\n",
    "    ax.scatter(X.spending_score, X.annual_income, c=clusters)\n",
    "    ax.set(title='k = {}'.format(k), xlabel='spending_score', ylabel='annual_income')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413fcff5-076c-41c7-894c-a1516320da9b",
   "metadata": {},
   "source": [
    "## Did scaling change our clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259d686-f1b0-4f94-8bcb-0c448b1f77cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "for cluster_n in train.cluster.sort_values().unique():\n",
    "    axs[0].scatter(train[train.cluster == cluster_n].spending_score, \n",
    "                train[train.cluster == cluster_n].annual_income, \n",
    "                label=f'cluster_{cluster_n}'\n",
    "               )\n",
    "axs[0].legend()\n",
    "axs[0].set(title=\"K-Means Unscaled Clusters\")\n",
    "\n",
    "for cluster_n in train_scaled.cluster.sort_values().unique():\n",
    "    axs[1].scatter(train_scaled[train_scaled.cluster == cluster_n].spending_score, \n",
    "                train_scaled[train_scaled.cluster == cluster_n].annual_income, \n",
    "                label=f'cluster_{cluster_n}'\n",
    "               )\n",
    "axs[1].legend()\n",
    "axs[1].set(title=\"K-Means Scaled Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47519d17",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "\n",
    "Lets try a similar process with DBSCAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0490b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(algorithm='auto', min_samples=4, eps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.fit(train[['spending_score', 'annual_income']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be987245",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dbcluster'] = dbscan.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef5bc9",
   "metadata": {},
   "source": [
    "DBSCAN assigns a value of `-1` to the cluster label of an observation that is considered \"noise\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a2bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bfe7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for cluster_n in train.dbcluster.sort_values().unique():\n",
    "    plt.scatter(train[train.dbcluster == cluster_n].spending_score, \n",
    "                train[train.dbcluster == cluster_n].annual_income, \n",
    "                label=f'cluster_{cluster_n}'\n",
    "               )\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"DBSCAN Clusters, eps=5, min_samples=4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a730fbbe",
   "metadata": {},
   "source": [
    "Okay, maybe we need to tune our DBSCAN a bit. There are two primary hyperparameters:\n",
    "\n",
    "$\\epsilon$ (epsilon): The distance scanned to identify if an adjacent observation is part of the same cluster.\n",
    "\n",
    "min_samples: The minimum number of datapoints that need to be closely grouped (determined by epsilon) before they are given their unique cluster identity/label.\n",
    "\n",
    "### min-samples\n",
    "\n",
    "Finding the optimal min-samples is a bit of trial and error, but there are some rules of thumb:\n",
    "\n",
    "- For two-dimensional data (only clustering on two features), use the default setting (min_samples = 4)\n",
    "- For data with more than two dimensions, choose 2 * the number of dimensions\n",
    "- If the data is noisy, choose a larger value for min_samples\n",
    "\n",
    "For our purposes, we will stick with the default. \n",
    "\n",
    "### $\\epsilon$ (epsilon)\n",
    "\n",
    "Finding the optimal value for epsilon can be handled according to [this paper](https://iopscience.iop.org/article/10.1088/1755-1315/31/1/012012/pdf).\n",
    "\n",
    "To find the optimal value for $\\epsilon$, we are going to create an elbow plot. We start by training a KNN model, and set the value of `k` equal to 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a807d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=2)\n",
    "neighbors_fit = neighbors.fit(train[['spending_score', 'annual_income']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a28821",
   "metadata": {},
   "source": [
    "KNN will calculate for us the average distance between each point in the data set and its nearest neighbor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a6dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = neighbors_fit.kneighbors(train[['spending_score', 'annual_income']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290176c8",
   "metadata": {},
   "source": [
    "In the array that is created, each row is an observation. \n",
    "\n",
    "|0|1|\n",
    "|---|---|\n",
    "|Distance to self|Distance to 1st closest neighbor|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89489cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db36fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b34fbe",
   "metadata": {},
   "source": [
    "We are now going to sort each column vertically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ed438",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.sort(distances, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56dbd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14add316",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62732690",
   "metadata": {},
   "source": [
    "Now lets just create a long 1-D list of all of the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3678a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = distances[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c77d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f7194",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(distances)\n",
    "plt.xlabel('Data Point')\n",
    "plt.ylabel('Epsilon')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a8cd7",
   "metadata": {},
   "source": [
    "The ideal value for $\\epsilon$ is the elbow of the curve. For the example above, it looks like 6 is a decent value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1575121",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan2 = DBSCAN(algorithm='auto', min_samples=4, eps=6)\n",
    "dbscan2.fit(train[['spending_score', 'annual_income']])\n",
    "train['dbcluster2'] = dbscan2.labels_\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be47780",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for cluster_n in train.dbcluster2.sort_values().unique():\n",
    "    plt.scatter(train[train.dbcluster2 == cluster_n].spending_score, \n",
    "                train[train.dbcluster2 == cluster_n].annual_income, \n",
    "                label=f'cluster_{cluster_n}'\n",
    "               )\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"DBSCAN Clusters, eps=6, min_samples=4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cf8028",
   "metadata": {},
   "source": [
    "Did changing epsilon from 5 to 6 improve our results? Debatable. \n",
    "\n",
    "Looks like KMeans is the winner here...at least with the unscaled data.\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Do your work for this exercise in a notebook named `modeling` within your `clustering-exercises` repository. For these exercises, YOU ONLY NEED TO DO KMEANS. If you have extra time, then you can play around with DBSCAN.\n",
    "\n",
    "1. Clustering with the Iris Dataset. Using this lesson as a guide, perform clustering on the iris dataset.\n",
    "    a. Choose features other than the ones used in the lesson.\n",
    "    b. Visualize the results of your clustering.\n",
    "    c. Use the elbow method to visually select a good value for k.\n",
    "    d. Repeat the clustering, this time with 3 different features.\n",
    "2. Use the techniques discussed in this lesson, as well as the insights gained from the exploration exercise to perform clustering on the mall customers dataset. Be sure to visualize your results!\n",
    "3. How does scaling impact the results of clustering? Compare k-means clustering results on scaled and unscaled data (you can choose any dataset for this exercise OR use the data/steps outlined in the bonus below). You can show how the resulting clusters differ either with descriptive statistics or visually.\n",
    "\n",
    "**Bonus**\n",
    "1. Read in the data from this google sheet: https://docs.google.com/spreadsheets/d/1j5EgXVTR5ikUj3G5ZCQmkq6ziz_gvtASGAdw23-5_6M/edit?usp=sharing\n",
    "2. Visualize the data and guess the number and shape of the clusters.\n",
    "3. Implement the KMeans algorithm on unscaled data and visualize the clusters.\n",
    "4. Repeat the step above but with scaled data.\n",
    "5. Write down the takeaways from this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e0b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
