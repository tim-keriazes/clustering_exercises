{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e336722c",
   "metadata": {},
   "source": [
    "# Ok, I have clusters... Now what?\n",
    "\n",
    "> \"The difference between a goat rodeo and making clusters is *using your clusters for deeper insight.*\" - Ryan Orsinger\n",
    "\n",
    "## Clusters are about providing options and insight\n",
    "- **Step 1:** Explore each cluster. \n",
    "    - Look at the relationship of cluster identity to your target variable if you have one (statistical testing, bivariate visualization)\n",
    "    - Look at the relationship of cluster identity to other variables (statistical testing, trivariate visualizations...think `relplot`)\n",
    "- **Step 2:** Name your clusters (if it makes sense to do so). Provide a verbal description of your clusters to help stakeholders understand.\n",
    "---\n",
    "Additional Uses:\n",
    "\n",
    "- **Option 1:** Dimensionality reduction. Some features with high degrees of correlation can be combined into clusters. \n",
    "- **Option 2:** Treat cluster names as a new target variable. As new data comes in, label that data with your clustering model as the first step of a greater process (customer segmentation, workflow, etc.)\n",
    "- **Option 3:** Use clustering as the stepping point to developing new questions you wouldn't know to ask until the data was clustered. Perform a deep EDA. \n",
    "- **Option 4:** Rather than feed your clusters as a feature of another model, take a \"many models\" approach and create multiple models that are uniquely tuned to one cluster subset at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46f0a8e",
   "metadata": {},
   "source": [
    "### Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5418f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv contains mall data\n",
    "df = pd.read_csv('https://gist.githubusercontent.com/ryanorsinger/cc276eea59e8295204d1f581c8da509f/raw/2388559aef7a0700eb31e7604351364b16e99653/mall_customers.csv', index_col=\"customer_id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88da4126",
   "metadata": {},
   "source": [
    "### Prepare\n",
    "- We are going to make some clusters, and prior exploration revealed that `gender` was not particularly insightful for this process. So we will drop `gender`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2707c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a5c21",
   "metadata": {},
   "source": [
    "For the purposes of the demo, I'm pretending that my df is my train dataset since I have so few observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfcc697",
   "metadata": {},
   "source": [
    "Scale features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136826c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the thing\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit the thing on train\n",
    "scaler.fit(train)\n",
    "\n",
    "# use the thing (scale train)\n",
    "train_scaled = scaler.transform(train)\n",
    "\n",
    "# turn the scaled array into a dataframe\n",
    "train_scaled = pd.DataFrame(train_scaled, columns=train.columns, index=train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1409efc7",
   "metadata": {},
   "source": [
    "If we also had validate and test datasets, I would have run the following lines of code to scale the data I have in validate and test.\n",
    "\n",
    "```python\n",
    "validate_scaled = scaler.transform(validate) \n",
    "test_scaled = scaler.transform(test) \n",
    "```\n",
    "\n",
    "And I could turn those arrays into dataframes as well:\n",
    "\n",
    "```python\n",
    "validate_scaled = pd.DataFrame(train_scaled, columns=validate.columns) \n",
    "test_scaled = pd.DataFrame(train_scaled, columns=test.columns)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ae12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ca0d2",
   "metadata": {},
   "source": [
    "We saw 5 clusters in our exploration of the data. Let's visualize an elbow method to see if inertia values supports our hunch that there are 5 clear groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot inertia vs k\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k, random_state=42).fit(train_scaled).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's move forward with k=5\n",
    "kmeans = KMeans(n_clusters = 5, random_state=42)\n",
    "kmeans.fit(train_scaled)\n",
    "\n",
    "# And assign the cluster number to a column on the dataframe\n",
    "train_scaled[\"cluster\"] = kmeans.predict(train_scaled)\n",
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee11c9",
   "metadata": {},
   "source": [
    "### So we have clusters. What are our options?\n",
    "- Step 1: Explore\n",
    "- Step 2: Name\n",
    "\n",
    "\n",
    "- Option 1: Simplify variables\n",
    "- Option 2: Use model and cluster names to classify new observations\n",
    "- Option 3: Deeper EDA\n",
    "- Option 4: Take a \"many models\" approach\n",
    "\n",
    "### Step 1: Explore each cluster to see how they are similar or different\n",
    "- Visualizations\n",
    "- Statistical tests\n",
    "\n",
    "> \"Take the time to get to know each cluster\" - Ryan Orsinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff101a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot out income vs. spending with regard to the cluster and age\n",
    "sns.relplot(data=train_scaled, x=\"annual_income\", y=\"spending_score\", col=\"cluster\", hue=\"age\", col_wrap=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb98d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby(\"cluster\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a7904",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby(\"cluster\").min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c95d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby(\"cluster\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae29b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby(\"cluster\").agg(['mean', 'max', 'min'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a6f70b",
   "metadata": {},
   "source": [
    "Run a statistical test to answer a question:\n",
    "\n",
    "$H_0$: There is no difference in spending score between cluster 0 and cluster 2.\n",
    "\n",
    "$H_a$: There is a difference in spending score between cluster 0 and cluster 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbfdfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the t-test\n",
    "t_value, p_value2 = stats.ttest_ind(train_scaled[train_scaled['cluster'] == 0].spending_score,\n",
    "                                    train_scaled[train_scaled['cluster'] == 2].spending_score)\n",
    "\n",
    "t_value, p_value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff1f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test my hypothesis\n",
    "alpha = 0.05\n",
    "\n",
    "if p_value2 < alpha:\n",
    "    print('We reject the null hypothesis.')\n",
    "else:\n",
    "    print('We fail to reject the null hypothesis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4baf4a",
   "metadata": {},
   "source": [
    "Spending score appears to be the same for these two groups (cluster 0 and cluster 2). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fead62",
   "metadata": {},
   "source": [
    "$H_0$: There is no difference in age between cluster 0 and cluster 2.\n",
    "\n",
    "$H_a$: There is a difference in age between cluster 0 and cluster 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the t-test\n",
    "t_value, p_value2 = stats.ttest_ind(train_scaled[train_scaled['cluster'] == 0].age,\n",
    "                                    train_scaled[train_scaled['cluster'] == 2].age)\n",
    "\n",
    "t_value, p_value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8da8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test my hypothesis\n",
    "alpha = 0.05\n",
    "\n",
    "if p_value2 < alpha:\n",
    "    print('We reject the null hypothesis.')\n",
    "else:\n",
    "    print('We fail to reject the null hypothesis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6fa42a",
   "metadata": {},
   "source": [
    "Their spending scores might be the same, but their ages are different. \n",
    "\n",
    "We can use this knowledge to help us in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55102ef7",
   "metadata": {},
   "source": [
    "### Step 2: Name the clusters with descriptive language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.cluster = train_scaled.cluster.map({\n",
    "    0: \"general-older\",\n",
    "    1: \"target\",\n",
    "    2: \"general-younger\",\n",
    "    3: \"frugal-high-income\",\n",
    "    4: \"spendthrift-young\",\n",
    "})\n",
    "\n",
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=train_scaled, x=\"annual_income\", y=\"spending_score\", col=\"cluster\", hue=\"age\", col_wrap=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd7254d",
   "metadata": {},
   "source": [
    "## Option 1: Use the clusters to simplify multiple other variables (dimensionality reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9f1750",
   "metadata": {},
   "source": [
    "- Since the cluster names make sense, we can use them instead of age, spending, and income.\n",
    "- This might be useful to reduce features (called dimensionality reduction)\n",
    "- Dimensionality reduction might likely help other model performance (regressions, classifications)\n",
    "- Simplifying our analysis to a handful of English terms can help with our storytelling.\n",
    "- Business and stakeholders, generally, crave simple answers. Clustering can help you with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e01368",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.drop(columns=[\"age\", \"annual_income\", \"spending_score\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9626ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff9376",
   "metadata": {},
   "source": [
    "### Option 2: Use cluster names as a target variable to classify new data\n",
    "\n",
    "Imagine that this dataset had other variables that our company could routinely collect by passive observation (think cookie tracking on websites):\n",
    "\n",
    "- `transportation`\n",
    "- `accompanying_individuals`\n",
    "- `hair_color`\n",
    "- `wedding_band`\n",
    "\n",
    "And data that we had to run a special survey to collect (the data that we clustered on):\n",
    "- `age`\n",
    "- `annual_income`\n",
    "- `spending_score`\n",
    "\n",
    "We added a new column, and we can treat that as a target variable now:\n",
    "- `cluster`\n",
    "\n",
    "We could built a **decision tree** model using the features that are easy to collect (`transportation`, `accompanying_individuals`, `hair_color`, `wedding_band`) to predict `cluster`. This could help us identify our target customers as they enter our mall without asking them the survey questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7678a3",
   "metadata": {},
   "source": [
    "### Option 3: Perform deeper EDA\n",
    "\n",
    "Sometimes the identification of clusters gives us additional questions we need to ask. Simpson's paradox, anyone?\n",
    "\n",
    "### Option 4: Create a Many Models Approach\n",
    "- Cluster 0 may have an upward linear trend between income and spending, best modeled by OLS linear regression\n",
    "- Cluster 1 may have an up then down polynomial trend between income and spending, best modeled by polynomial linear regression\n",
    "- Cluster 2 may be more random, best modeled by a regression tree\n",
    "\n",
    "In this way, we can create a machine learning pipeline that sends customers to different prediction models based on their cluster membership.\n",
    "\n",
    "**Remember:**\n",
    "- We can dive into each cluster individually w/ exploration\n",
    "- stats + hypothesis testing\n",
    "- visualizations for each cluster, comparing/contrasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1dc49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
